{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "#1 - Cargar tips y mostrar algo de info\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "print(\"\\n Cinco filas:\\n\", tips.head())\n",
    "print(\"\\n Información de tips: \\n\")\n",
    "print(tips.info())\n",
    "print(\"\\n Estadísticas: \\n\", tips.describe())\n",
    "\n",
    "#2 - Limpieza de datos\n",
    "print(\"\\n Valores nulos: \\n\", tips.isnull().sum())\n",
    "print(\"Filas duplicadas:\", tips.duplicated().sum())\n",
    "\n",
    "# Se supone que el dataset tips no tiene valores nulos ni duplicados\n",
    "tips.dropna(inplace=True)\n",
    "tips.drop_duplicates(inplace=True)\n",
    "\n",
    "# outliers -  lo hago ccn IQR por si tips es muy asimétrico para hacerlo con cuartiles, si fuese más simétrico, podría hacerlo con Z-score\n",
    "Q1_tip = tips['tip'].quantile(0.25)\n",
    "Q3_tip = tips['tip'].quantile(0.75)\n",
    "IQR_tip = Q3_tip - Q1_tip #este es el IQR\n",
    "\n",
    "#esto para poner los limits\n",
    "lower_bound_tip = Q1_tip - 1.5 * IQR_tip\n",
    "upper_bound_tip = Q3_tip + 1.5 * IQR_tip\n",
    "\n",
    "before_iqr_rows = tips.shape[0]\n",
    "# para filtrar por tips\n",
    "tips = tips[(tips['tip'] >= lower_bound_tip) & (tips['tip'] <= upper_bound_tip)]\n",
    "after_iqr_rows = tips.shape[0]\n",
    "print(f\"\\n IQR en la columna tip \\n\")\n",
    "print(f\"FIlas antes de IQR : {before_iqr_rows}\")\n",
    "print(f\"Filas después de IQR: {after_iqr_rows}\")\n",
    "\n",
    "#3 - EDA\n",
    "#univariante - Histograma\n",
    "plt.hist(tips['total_bill'], bins=20, color='purple', edgecolor='black')\n",
    "plt.title(\"Histograma de 'total_bill'\")\n",
    "plt.xlabel(\"Total Bill\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.savefig(\"histograma.png\")\n",
    "plt.close()\n",
    "\n",
    "#bivariante - Dispersion\n",
    "sns.scatterplot(data=tips, x='total_bill', y='tip', hue='sex', palette='Purples')\n",
    "plt.title(\"Dispersion total_bill - tip\")\n",
    "plt.xlabel(\"Total Bill\")\n",
    "plt.ylabel(\"Tip\")\n",
    "plt.savefig(\"dispersion.png\")\n",
    "plt.close()\n",
    "\n",
    "# multivariant - Heatmap de correlación\n",
    "numeric_data = tips.select_dtypes(include=[np.number])\n",
    "corr_matrix = numeric_data.corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"Purples\")\n",
    "plt.title(\"Mapa de correlación\")\n",
    "plt.savefig(\"mapacalor.png\")\n",
    "plt.close()\n",
    "# en un entorno Jupyter, podría usar plt.show() en vez de plt.savefig() y ver todo en una ventana con flechas.\n",
    "\n",
    "# 4 - Preparación de datos\t\n",
    "# para tranformar a datos numéricos, drop first porque en el caso del día aunque borres el primero, si el resto son 0, se sabe que el primero es el correcto, como si fuese por descarte\n",
    "tips_dummies = pd.get_dummies(tips, columns=['sex','smoker','day','time'], drop_first=True)\n",
    "\n",
    "# para las características y la variable objetivo\n",
    "X = tips_dummies.drop('tip', axis=1)\n",
    "y = tips_dummies['tip']\n",
    "\n",
    "# split de entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=11\n",
    "    #para el random state, si no se pone, cada vez que se ejecute, se obtienen resultados diferentes o si pongo NONE\n",
    ")\n",
    "\n",
    "# para escalar las variables numéricas\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['total_bill', 'size']\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "#para la prueba sin fit, los datos de prueba no los tiene que ver el modelo\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "#5-  Modelado\n",
    "# he utilizado este par, uno lineal y otro de arbol de decisión\n",
    "modelos = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=11)\n",
    "    #Igual que antes, para el random state, si no se pone, cada vez que se ejecute, se obtienen resultados diferentes o si pongo NONE\n",
    "}\n",
    "\n",
    "for nombre_modelo, modelo in modelos.items():\n",
    "    #se entrena el modelo con los datos del entrenamiento\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    #Seria asi, pero me da fallo por la V. de Scikit-learn en mi entorno: srmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    #Asi es de manera manual\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n Modelo: {nombre_modelo}\")\n",
    "    print(f\"  MAE  : {mae:.2f}\")\n",
    "    print(f\"  RMSE : {rmse:.2f}\")\n",
    "    print(f\"  R²   : {r2:.2f}\")\n",
    "\n",
    "#  Modelo: LinearRegression\n",
    "#   MAE  : 0.56\n",
    "#   RMSE : 0.72\n",
    "#   R²   : 0.43\n",
    "\n",
    "#  Modelo: RandomForestRegressor\n",
    "#   MAE  : 0.51\n",
    "#   RMSE : 0.75\n",
    "#   R²   : 0.37\n",
    "\n",
    "# Estos son los resultados que he obtenido en mi entorno, en este caso dependiendo de las métricas que se quieran priorizar, pero en general pese a que en el modelo\n",
    "# de regresión lineal el MAE para los errores absolutos pequeños es mayor, el RMSE para errores grandes es menor, y el R² se acerca más a 1.\n",
    "# Es decir, que en general, el modelo de regresión lineal es mejor que el de arbol de decisión, aunque ambos son relativamente malos, el R² es bajo en ambos casos."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
